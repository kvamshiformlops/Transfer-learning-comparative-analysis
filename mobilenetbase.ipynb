{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"]=\"jax\" \nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\"\nos.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:10:52.603744Z","iopub.execute_input":"2025-04-06T09:10:52.604105Z","iopub.status.idle":"2025-04-06T09:10:52.608378Z","shell.execute_reply.started":"2025-04-06T09:10:52.604058Z","shell.execute_reply":"2025-04-06T09:10:52.607471Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.applications.mobilenet import preprocess_input,MobileNet\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:10:54.120620Z","iopub.execute_input":"2025-04-06T09:10:54.120925Z","iopub.status.idle":"2025-04-06T09:10:57.763744Z","shell.execute_reply.started":"2025-04-06T09:10:54.120904Z","shell.execute_reply":"2025-04-06T09:10:57.762807Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"(x_train,y_train),(x_test,y_test)=tf.keras.datasets.cifar100.load_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:10:59.957694Z","iopub.execute_input":"2025-04-06T09:10:59.958411Z","iopub.status.idle":"2025-04-06T09:11:00.773215Z","shell.execute_reply.started":"2025-04-06T09:10:59.958376Z","shell.execute_reply":"2025-04-06T09:11:00.772536Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"x_train=tf.image.resize(x_train,(128,128)).numpy()\nx_test=tf.image.resize(x_test,(128,128)).numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:11:02.017453Z","iopub.execute_input":"2025-04-06T09:11:02.017795Z","iopub.status.idle":"2025-04-06T09:11:24.357152Z","shell.execute_reply.started":"2025-04-06T09:11:02.017769Z","shell.execute_reply":"2025-04-06T09:11:24.356403Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"x_train=tf.keras.applications.mobilenet.preprocess_input(x_train)\nx_test=tf.keras.applications.mobilenet.preprocess_input(x_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:11:35.183332Z","iopub.execute_input":"2025-04-06T09:11:35.183678Z","iopub.status.idle":"2025-04-06T09:11:38.954266Z","shell.execute_reply.started":"2025-04-06T09:11:35.183652Z","shell.execute_reply":"2025-04-06T09:11:38.953262Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,random_state=42,test_size=0.25,stratify=y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:11:45.037746Z","iopub.execute_input":"2025-04-06T09:11:45.038090Z","iopub.status.idle":"2025-04-06T09:11:48.187542Z","shell.execute_reply.started":"2025-04-06T09:11:45.038064Z","shell.execute_reply":"2025-04-06T09:11:48.186644Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"datagen=ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    zoom_range=0.2,\n    shear_range=0.2,\n    fill_mode='nearest'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:11:51.260081Z","iopub.execute_input":"2025-04-06T09:11:51.260422Z","iopub.status.idle":"2025-04-06T09:11:51.264800Z","shell.execute_reply.started":"2025-04-06T09:11:51.260396Z","shell.execute_reply":"2025-04-06T09:11:51.263529Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"base_model=MobileNet(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(128,128,3)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:11:54.643984Z","iopub.execute_input":"2025-04-06T09:11:54.644329Z","iopub.status.idle":"2025-04-06T09:11:59.186162Z","shell.execute_reply.started":"2025-04-06T09:11:54.644275Z","shell.execute_reply":"2025-04-06T09:11:59.185096Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_128_tf_no_top.h5\n\u001b[1m17225924/17225924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"base_model.trainable=False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:12:32.117926Z","iopub.execute_input":"2025-04-06T09:12:32.118250Z","iopub.status.idle":"2025-04-06T09:12:32.123092Z","shell.execute_reply.started":"2025-04-06T09:12:32.118226Z","shell.execute_reply":"2025-04-06T09:12:32.122107Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"model=models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(1024,activation='silu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n    layers.Dense(512,activation='silu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    layers.Dense(256,activation='silu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(100,activation='softmax') \n])\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:12:33.119377Z","iopub.execute_input":"2025-04-06T09:12:33.119712Z","iopub.status.idle":"2025-04-06T09:12:34.227377Z","shell.execute_reply.started":"2025-04-06T09:12:33.119687Z","shell.execute_reply":"2025-04-06T09:12:34.226462Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ mobilenet_1.00_128 (\u001b[38;5;33mFunctional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │       \u001b[38;5;34m3,228,864\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m1,049,600\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │           \u001b[38;5;34m4,096\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m524,800\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m25,700\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ mobilenet_1.00_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,228,864</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,700</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,967,460\u001b[0m (18.95 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,967,460</span> (18.95 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,735,012\u001b[0m (6.62 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,735,012</span> (6.62 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,232,448\u001b[0m (12.33 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,232,448</span> (12.33 MB)\n</pre>\n"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate=1e-4),loss='sparse_categorical_crossentropy',metrics=[\"accuracy\"],jit_compile=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:12:39.285463Z","iopub.execute_input":"2025-04-06T09:12:39.285839Z","iopub.status.idle":"2025-04-06T09:12:39.319854Z","shell.execute_reply.started":"2025-04-06T09:12:39.285812Z","shell.execute_reply":"2025-04-06T09:12:39.318837Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"early_stopper=EarlyStopping(restore_best_weights=True,monitor=\"val_loss\",patience=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:12:40.514419Z","iopub.execute_input":"2025-04-06T09:12:40.514774Z","iopub.status.idle":"2025-04-06T09:12:40.518766Z","shell.execute_reply.started":"2025-04-06T09:12:40.514750Z","shell.execute_reply":"2025-04-06T09:12:40.517825Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"history=model.fit(datagen.flow(x_train,y_train),epochs=30,batch_size=32,callbacks=[early_stopper],validation_data=[x_val,y_val],verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:12:41.846102Z","iopub.execute_input":"2025-04-06T09:12:41.846459Z","iopub.status.idle":"2025-04-06T10:26:19.717189Z","shell.execute_reply.started":"2025-04-06T09:12:41.846428Z","shell.execute_reply":"2025-04-06T10:26:19.716179Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 137ms/step - accuracy: 0.0647 - loss: 4.6487 - val_accuracy: 0.4139 - val_loss: 2.3519\nEpoch 2/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 127ms/step - accuracy: 0.2582 - loss: 3.0394 - val_accuracy: 0.5093 - val_loss: 1.8612\nEpoch 3/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 126ms/step - accuracy: 0.3343 - loss: 2.5905 - val_accuracy: 0.5512 - val_loss: 1.6507\nEpoch 4/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 126ms/step - accuracy: 0.3914 - loss: 2.3198 - val_accuracy: 0.5776 - val_loss: 1.5266\nEpoch 5/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 125ms/step - accuracy: 0.4151 - loss: 2.2009 - val_accuracy: 0.5976 - val_loss: 1.4423\nEpoch 6/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 125ms/step - accuracy: 0.4428 - loss: 2.0973 - val_accuracy: 0.6071 - val_loss: 1.3933\nEpoch 7/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 126ms/step - accuracy: 0.4555 - loss: 2.0306 - val_accuracy: 0.6151 - val_loss: 1.3512\nEpoch 8/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 126ms/step - accuracy: 0.4762 - loss: 1.9632 - val_accuracy: 0.6225 - val_loss: 1.3163\nEpoch 9/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 127ms/step - accuracy: 0.4862 - loss: 1.9120 - val_accuracy: 0.6333 - val_loss: 1.2933\nEpoch 10/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 126ms/step - accuracy: 0.4966 - loss: 1.8613 - val_accuracy: 0.6359 - val_loss: 1.2820\nEpoch 11/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 125ms/step - accuracy: 0.4994 - loss: 1.8339 - val_accuracy: 0.6398 - val_loss: 1.2560\nEpoch 12/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 126ms/step - accuracy: 0.5160 - loss: 1.7907 - val_accuracy: 0.6422 - val_loss: 1.2480\nEpoch 13/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 127ms/step - accuracy: 0.5156 - loss: 1.7925 - val_accuracy: 0.6472 - val_loss: 1.2307\nEpoch 14/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 127ms/step - accuracy: 0.5291 - loss: 1.7258 - val_accuracy: 0.6474 - val_loss: 1.2238\nEpoch 15/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 128ms/step - accuracy: 0.5359 - loss: 1.7114 - val_accuracy: 0.6517 - val_loss: 1.2064\nEpoch 16/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 126ms/step - accuracy: 0.5345 - loss: 1.6946 - val_accuracy: 0.6544 - val_loss: 1.1973\nEpoch 17/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 126ms/step - accuracy: 0.5420 - loss: 1.6701 - val_accuracy: 0.6558 - val_loss: 1.1896\nEpoch 18/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 125ms/step - accuracy: 0.5467 - loss: 1.6540 - val_accuracy: 0.6586 - val_loss: 1.1848\nEpoch 19/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 125ms/step - accuracy: 0.5471 - loss: 1.6425 - val_accuracy: 0.6631 - val_loss: 1.1784\nEpoch 20/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 125ms/step - accuracy: 0.5510 - loss: 1.6258 - val_accuracy: 0.6640 - val_loss: 1.1659\nEpoch 21/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 123ms/step - accuracy: 0.5606 - loss: 1.5963 - val_accuracy: 0.6638 - val_loss: 1.1681\nEpoch 22/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 124ms/step - accuracy: 0.5611 - loss: 1.5917 - val_accuracy: 0.6668 - val_loss: 1.1591\nEpoch 23/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 122ms/step - accuracy: 0.5674 - loss: 1.5706 - val_accuracy: 0.6672 - val_loss: 1.1528\nEpoch 24/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 122ms/step - accuracy: 0.5749 - loss: 1.5424 - val_accuracy: 0.6707 - val_loss: 1.1536\nEpoch 25/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 124ms/step - accuracy: 0.5681 - loss: 1.5497 - val_accuracy: 0.6678 - val_loss: 1.1482\nEpoch 26/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 123ms/step - accuracy: 0.5709 - loss: 1.5367 - val_accuracy: 0.6702 - val_loss: 1.1436\nEpoch 27/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 123ms/step - accuracy: 0.5772 - loss: 1.5180 - val_accuracy: 0.6700 - val_loss: 1.1501\nEpoch 28/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 124ms/step - accuracy: 0.5853 - loss: 1.5064 - val_accuracy: 0.6727 - val_loss: 1.1349\nEpoch 29/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 123ms/step - accuracy: 0.5867 - loss: 1.4880 - val_accuracy: 0.6735 - val_loss: 1.1383\nEpoch 30/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 122ms/step - accuracy: 0.5835 - loss: 1.4930 - val_accuracy: 0.6737 - val_loss: 1.1350\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import numpy as np\ny_pred=model.predict(x_test)\ny_pred_class=np.argmax(y_pred,axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:26:31.681768Z","iopub.execute_input":"2025-04-06T10:26:31.682105Z","iopub.status.idle":"2025-04-06T10:26:36.604181Z","shell.execute_reply.started":"2025-04-06T10:26:31.682077Z","shell.execute_reply":"2025-04-06T10:26:36.603453Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"test_loss,test_accuracy=model.evaluate(x_test,y_test)\nprint(f\"Test accuracy: {test_accuracy * 100:.4f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:26:43.457002Z","iopub.execute_input":"2025-04-06T10:26:43.457347Z","iopub.status.idle":"2025-04-06T10:26:47.656612Z","shell.execute_reply.started":"2025-04-06T10:26:43.457320Z","shell.execute_reply":"2025-04-06T10:26:47.655863Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.6762 - loss: 1.1347\nTest accuracy: 67.4500%\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"val_loss,val_accuracy=model.evaluate(x_val,y_val)\nprint(f\"Validation accuracy: {val_accuracy * 100:.4f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:26:50.829542Z","iopub.execute_input":"2025-04-06T10:26:50.829865Z","iopub.status.idle":"2025-04-06T10:26:53.608439Z","shell.execute_reply.started":"2025-04-06T10:26:50.829838Z","shell.execute_reply":"2025-04-06T10:26:53.607710Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6691 - loss: 1.1420\nValidation accuracy: 67.2720%\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score,classification_report\n\n\naccuracy=accuracy_score(y_test,y_pred_class)\nprecision=precision_score(y_test,y_pred_class,average='weighted')\nrecall=recall_score(y_test,y_pred_class,average='weighted')\nf1=f1_score(y_test,y_pred_class,average='weighted')\n\n\nprint(\"\\nPerformance Metrics Breakdown for MobileNetBase:\")\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1-Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:26:56.464256Z","iopub.execute_input":"2025-04-06T10:26:56.464629Z","iopub.status.idle":"2025-04-06T10:26:56.486853Z","shell.execute_reply.started":"2025-04-06T10:26:56.464601Z","shell.execute_reply":"2025-04-06T10:26:56.485833Z"}},"outputs":[{"name":"stdout","text":"\nPerformance Metrics Breakdown for MobileNetBase:\nAccuracy: 0.6745\nPrecision: 0.6785\nRecall: 0.6745\nF1-Score: 0.6726\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"print(\"\\nDetailed Classification Report for MobileNetBase:\")\nprint(classification_report(y_test,y_pred_class))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:26:58.715378Z","iopub.execute_input":"2025-04-06T10:26:58.715664Z","iopub.status.idle":"2025-04-06T10:26:58.739809Z","shell.execute_reply.started":"2025-04-06T10:26:58.715642Z","shell.execute_reply":"2025-04-06T10:26:58.738977Z"}},"outputs":[{"name":"stdout","text":"\nDetailed Classification Report for MobileNetBase:\n              precision    recall  f1-score   support\n\n           0       0.84      0.91      0.87       100\n           1       0.72      0.70      0.71       100\n           2       0.58      0.49      0.53       100\n           3       0.61      0.48      0.54       100\n           4       0.39      0.47      0.43       100\n           5       0.61      0.80      0.69       100\n           6       0.73      0.62      0.67       100\n           7       0.76      0.65      0.70       100\n           8       0.82      0.79      0.81       100\n           9       0.89      0.76      0.82       100\n          10       0.61      0.58      0.59       100\n          11       0.49      0.47      0.48       100\n          12       0.73      0.67      0.70       100\n          13       0.67      0.49      0.57       100\n          14       0.73      0.72      0.73       100\n          15       0.63      0.75      0.68       100\n          16       0.73      0.77      0.75       100\n          17       0.77      0.82      0.79       100\n          18       0.84      0.56      0.67       100\n          19       0.73      0.58      0.65       100\n          20       0.88      0.84      0.86       100\n          21       0.66      0.88      0.76       100\n          22       0.79      0.82      0.80       100\n          23       0.80      0.68      0.74       100\n          24       0.82      0.89      0.86       100\n          25       0.79      0.57      0.66       100\n          26       0.63      0.71      0.67       100\n          27       0.44      0.55      0.49       100\n          28       0.78      0.83      0.80       100\n          29       0.74      0.67      0.71       100\n          30       0.60      0.58      0.59       100\n          31       0.62      0.67      0.64       100\n          32       0.62      0.60      0.61       100\n          33       0.61      0.66      0.63       100\n          34       0.61      0.73      0.67       100\n          35       0.38      0.38      0.38       100\n          36       0.71      0.70      0.71       100\n          37       0.65      0.71      0.68       100\n          38       0.46      0.50      0.48       100\n          39       0.89      0.88      0.88       100\n          40       0.71      0.67      0.69       100\n          41       0.85      0.81      0.83       100\n          42       0.59      0.68      0.63       100\n          43       0.62      0.76      0.68       100\n          44       0.51      0.47      0.49       100\n          45       0.49      0.53      0.51       100\n          46       0.57      0.47      0.51       100\n          47       0.64      0.55      0.59       100\n          48       0.86      0.88      0.87       100\n          49       0.81      0.77      0.79       100\n          50       0.44      0.40      0.42       100\n          51       0.64      0.77      0.70       100\n          52       0.51      0.82      0.63       100\n          53       0.84      0.91      0.87       100\n          54       0.63      0.68      0.65       100\n          55       0.46      0.42      0.44       100\n          56       0.77      0.84      0.80       100\n          57       0.78      0.68      0.73       100\n          58       0.86      0.80      0.83       100\n          59       0.82      0.54      0.65       100\n          60       0.77      0.85      0.81       100\n          61       0.66      0.73      0.69       100\n          62       0.67      0.75      0.71       100\n          63       0.62      0.59      0.61       100\n          64       0.56      0.43      0.49       100\n          65       0.46      0.49      0.47       100\n          66       0.58      0.56      0.57       100\n          67       0.54      0.60      0.57       100\n          68       0.82      0.86      0.84       100\n          69       0.80      0.78      0.79       100\n          70       0.68      0.67      0.67       100\n          71       0.72      0.74      0.73       100\n          72       0.47      0.32      0.38       100\n          73       0.51      0.59      0.55       100\n          74       0.45      0.44      0.44       100\n          75       0.78      0.83      0.81       100\n          76       0.88      0.80      0.84       100\n          77       0.71      0.68      0.69       100\n          78       0.62      0.75      0.68       100\n          79       0.76      0.68      0.72       100\n          80       0.57      0.48      0.52       100\n          81       0.53      0.80      0.64       100\n          82       0.93      0.85      0.89       100\n          83       0.69      0.63      0.66       100\n          84       0.71      0.65      0.68       100\n          85       0.74      0.87      0.80       100\n          86       0.78      0.79      0.79       100\n          87       0.87      0.87      0.87       100\n          88       0.68      0.73      0.71       100\n          89       0.72      0.87      0.79       100\n          90       0.72      0.77      0.74       100\n          91       0.75      0.75      0.75       100\n          92       0.62      0.53      0.57       100\n          93       0.69      0.56      0.62       100\n          94       0.85      0.91      0.88       100\n          95       0.71      0.65      0.68       100\n          96       0.53      0.42      0.47       100\n          97       0.70      0.68      0.69       100\n          98       0.46      0.38      0.42       100\n          99       0.74      0.74      0.74       100\n\n    accuracy                           0.67     10000\n   macro avg       0.68      0.67      0.67     10000\nweighted avg       0.68      0.67      0.67     10000\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}