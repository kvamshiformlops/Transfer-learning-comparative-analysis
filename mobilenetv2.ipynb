{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"]=\"jax\" \nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\"\nos.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:40:07.995153Z","iopub.execute_input":"2025-04-06T10:40:07.995516Z","iopub.status.idle":"2025-04-06T10:40:07.999746Z","shell.execute_reply.started":"2025-04-06T10:40:07.995486Z","shell.execute_reply":"2025-04-06T10:40:07.998756Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input,MobileNetV2\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:40:08.000988Z","iopub.execute_input":"2025-04-06T10:40:08.001220Z","iopub.status.idle":"2025-04-06T10:40:11.293676Z","shell.execute_reply.started":"2025-04-06T10:40:08.001200Z","shell.execute_reply":"2025-04-06T10:40:11.292732Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"(x_train,y_train),(x_test,y_test)=tf.keras.datasets.cifar100.load_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:40:11.295482Z","iopub.execute_input":"2025-04-06T10:40:11.296075Z","iopub.status.idle":"2025-04-06T10:40:18.581710Z","shell.execute_reply.started":"2025-04-06T10:40:11.296048Z","shell.execute_reply":"2025-04-06T10:40:18.580760Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"x_train=tf.image.resize(x_train,(128,128)).numpy()\nx_test=tf.image.resize(x_test,(128,128)).numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:40:18.582984Z","iopub.execute_input":"2025-04-06T10:40:18.583223Z","iopub.status.idle":"2025-04-06T10:40:40.214801Z","shell.execute_reply.started":"2025-04-06T10:40:18.583201Z","shell.execute_reply":"2025-04-06T10:40:40.213685Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"x_train=tf.keras.applications.mobilenet.preprocess_input(x_train)\nx_test=tf.keras.applications.mobilenet.preprocess_input(x_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:40:40.215643Z","iopub.execute_input":"2025-04-06T10:40:40.215879Z","iopub.status.idle":"2025-04-06T10:40:43.789815Z","shell.execute_reply.started":"2025-04-06T10:40:40.215849Z","shell.execute_reply":"2025-04-06T10:40:43.789071Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,random_state=42,test_size=0.25,stratify=y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:40:43.790675Z","iopub.execute_input":"2025-04-06T10:40:43.790984Z","iopub.status.idle":"2025-04-06T10:40:46.809249Z","shell.execute_reply.started":"2025-04-06T10:40:43.790952Z","shell.execute_reply":"2025-04-06T10:40:46.808449Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"datagen=ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    zoom_range=0.2,\n    shear_range=0.2,\n    fill_mode='nearest'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:40:46.810986Z","iopub.execute_input":"2025-04-06T10:40:46.811271Z","iopub.status.idle":"2025-04-06T10:40:46.815390Z","shell.execute_reply.started":"2025-04-06T10:40:46.811248Z","shell.execute_reply":"2025-04-06T10:40:46.814479Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"base_model=MobileNetV2(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(128,128,3)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:40:46.817081Z","iopub.execute_input":"2025-04-06T10:40:46.817266Z","iopub.status.idle":"2025-04-06T10:40:55.281037Z","shell.execute_reply.started":"2025-04-06T10:40:46.817248Z","shell.execute_reply":"2025-04-06T10:40:55.280355Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"base_model.trainable=False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:40:55.281943Z","iopub.execute_input":"2025-04-06T10:40:55.282148Z","iopub.status.idle":"2025-04-06T10:40:55.287082Z","shell.execute_reply.started":"2025-04-06T10:40:55.282130Z","shell.execute_reply":"2025-04-06T10:40:55.286173Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"model=models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(1024,activation='silu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n    layers.Dense(512,activation='silu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    layers.Dense(256,activation='silu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(100,activation='softmax') \n])\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:40:55.287942Z","iopub.execute_input":"2025-04-06T10:40:55.288226Z","iopub.status.idle":"2025-04-06T10:40:56.274943Z","shell.execute_reply.started":"2025-04-06T10:40:55.288196Z","shell.execute_reply":"2025-04-06T10:40:56.274029Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ mobilenetv2_1.00_128 (\u001b[38;5;33mFunctional\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m2,257,984\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m1,311,744\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │           \u001b[38;5;34m4,096\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m524,800\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m25,700\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ mobilenetv2_1.00_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,744</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,700</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,258,724\u001b[0m (16.25 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,258,724</span> (16.25 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,997,156\u001b[0m (7.62 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,997,156</span> (7.62 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,261,568\u001b[0m (8.63 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,261,568</span> (8.63 MB)\n</pre>\n"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate=1e-4),loss='sparse_categorical_crossentropy',metrics=[\"accuracy\"],jit_compile=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:40:56.275859Z","iopub.execute_input":"2025-04-06T10:40:56.276186Z","iopub.status.idle":"2025-04-06T10:40:56.307956Z","shell.execute_reply.started":"2025-04-06T10:40:56.276153Z","shell.execute_reply":"2025-04-06T10:40:56.307354Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"early_stopper=EarlyStopping(restore_best_weights=True,monitor=\"val_loss\",patience=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:40:56.308640Z","iopub.execute_input":"2025-04-06T10:40:56.308829Z","iopub.status.idle":"2025-04-06T10:40:56.312403Z","shell.execute_reply.started":"2025-04-06T10:40:56.308811Z","shell.execute_reply":"2025-04-06T10:40:56.311521Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"history=model.fit(datagen.flow(x_train,y_train),epochs=30,batch_size=32,callbacks=[early_stopper],validation_data=[x_val,y_val],verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:40:56.313061Z","iopub.execute_input":"2025-04-06T10:40:56.313247Z","iopub.status.idle":"2025-04-06T11:49:08.402735Z","shell.execute_reply.started":"2025-04-06T10:40:56.313230Z","shell.execute_reply":"2025-04-06T11:49:08.401958Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 129ms/step - accuracy: 0.0716 - loss: 4.6216 - val_accuracy: 0.4328 - val_loss: 2.2683\nEpoch 2/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 116ms/step - accuracy: 0.2698 - loss: 2.9800 - val_accuracy: 0.5128 - val_loss: 1.8302\nEpoch 3/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 116ms/step - accuracy: 0.3469 - loss: 2.5596 - val_accuracy: 0.5488 - val_loss: 1.6488\nEpoch 4/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 116ms/step - accuracy: 0.3935 - loss: 2.3298 - val_accuracy: 0.5652 - val_loss: 1.5584\nEpoch 5/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 116ms/step - accuracy: 0.4164 - loss: 2.2172 - val_accuracy: 0.5748 - val_loss: 1.5069\nEpoch 6/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 115ms/step - accuracy: 0.4393 - loss: 2.1234 - val_accuracy: 0.5908 - val_loss: 1.4535\nEpoch 7/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 116ms/step - accuracy: 0.4510 - loss: 2.0529 - val_accuracy: 0.6002 - val_loss: 1.4276\nEpoch 8/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 115ms/step - accuracy: 0.4642 - loss: 1.9980 - val_accuracy: 0.6062 - val_loss: 1.4004\nEpoch 9/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 115ms/step - accuracy: 0.4786 - loss: 1.9519 - val_accuracy: 0.6112 - val_loss: 1.3809\nEpoch 10/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 116ms/step - accuracy: 0.4854 - loss: 1.9121 - val_accuracy: 0.6122 - val_loss: 1.3680\nEpoch 11/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 116ms/step - accuracy: 0.4961 - loss: 1.8681 - val_accuracy: 0.6187 - val_loss: 1.3476\nEpoch 12/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 116ms/step - accuracy: 0.4935 - loss: 1.8628 - val_accuracy: 0.6205 - val_loss: 1.3396\nEpoch 13/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 115ms/step - accuracy: 0.5031 - loss: 1.8385 - val_accuracy: 0.6283 - val_loss: 1.3208\nEpoch 14/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 116ms/step - accuracy: 0.5075 - loss: 1.7999 - val_accuracy: 0.6311 - val_loss: 1.3159\nEpoch 15/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 116ms/step - accuracy: 0.5168 - loss: 1.7830 - val_accuracy: 0.6291 - val_loss: 1.3130\nEpoch 16/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 116ms/step - accuracy: 0.5163 - loss: 1.7767 - val_accuracy: 0.6336 - val_loss: 1.3005\nEpoch 17/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 115ms/step - accuracy: 0.5216 - loss: 1.7637 - val_accuracy: 0.6331 - val_loss: 1.2986\nEpoch 18/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 116ms/step - accuracy: 0.5232 - loss: 1.7505 - val_accuracy: 0.6353 - val_loss: 1.2904\nEpoch 19/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 115ms/step - accuracy: 0.5328 - loss: 1.7140 - val_accuracy: 0.6362 - val_loss: 1.2807\nEpoch 20/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 115ms/step - accuracy: 0.5364 - loss: 1.6930 - val_accuracy: 0.6382 - val_loss: 1.2768\nEpoch 21/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 116ms/step - accuracy: 0.5412 - loss: 1.6684 - val_accuracy: 0.6398 - val_loss: 1.2713\nEpoch 22/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 116ms/step - accuracy: 0.5386 - loss: 1.6778 - val_accuracy: 0.6398 - val_loss: 1.2733\nEpoch 23/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 116ms/step - accuracy: 0.5411 - loss: 1.6661 - val_accuracy: 0.6432 - val_loss: 1.2675\nEpoch 24/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 116ms/step - accuracy: 0.5525 - loss: 1.6217 - val_accuracy: 0.6428 - val_loss: 1.2640\nEpoch 25/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 115ms/step - accuracy: 0.5576 - loss: 1.6126 - val_accuracy: 0.6425 - val_loss: 1.2678\nEpoch 26/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 116ms/step - accuracy: 0.5500 - loss: 1.6304 - val_accuracy: 0.6440 - val_loss: 1.2608\nEpoch 27/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 116ms/step - accuracy: 0.5559 - loss: 1.6191 - val_accuracy: 0.6460 - val_loss: 1.2530\nEpoch 28/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 116ms/step - accuracy: 0.5586 - loss: 1.5952 - val_accuracy: 0.6452 - val_loss: 1.2502\nEpoch 29/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 115ms/step - accuracy: 0.5687 - loss: 1.5743 - val_accuracy: 0.6466 - val_loss: 1.2422\nEpoch 30/30\n\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 115ms/step - accuracy: 0.5655 - loss: 1.5853 - val_accuracy: 0.6474 - val_loss: 1.2441\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import numpy as np\ny_pred=model.predict(x_test)\ny_pred_class=np.argmax(y_pred,axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:49:08.403889Z","iopub.execute_input":"2025-04-06T11:49:08.404099Z","iopub.status.idle":"2025-04-06T11:49:15.700166Z","shell.execute_reply.started":"2025-04-06T11:49:08.404078Z","shell.execute_reply":"2025-04-06T11:49:15.699503Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"test_loss,test_accuracy=model.evaluate(x_test,y_test)\nprint(f\"Test accuracy: {test_accuracy * 100:.4f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:49:15.700959Z","iopub.execute_input":"2025-04-06T11:49:15.701247Z","iopub.status.idle":"2025-04-06T11:49:20.815493Z","shell.execute_reply.started":"2025-04-06T11:49:15.701214Z","shell.execute_reply":"2025-04-06T11:49:20.814694Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.6489 - loss: 1.2344\nTest accuracy: 64.7400%\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"val_loss,val_accuracy=model.evaluate(x_val,y_val)\nprint(f\"Validation accuracy: {val_accuracy * 100:.4f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:49:20.816361Z","iopub.execute_input":"2025-04-06T11:49:20.816642Z","iopub.status.idle":"2025-04-06T11:49:23.900181Z","shell.execute_reply.started":"2025-04-06T11:49:20.816616Z","shell.execute_reply":"2025-04-06T11:49:23.899182Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6437 - loss: 1.2521\nValidation accuracy: 64.6640%\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score,classification_report\n\n\naccuracy=accuracy_score(y_test,y_pred_class)\nprecision=precision_score(y_test,y_pred_class,average='weighted')\nrecall=recall_score(y_test,y_pred_class,average='weighted')\nf1=f1_score(y_test,y_pred_class,average='weighted')\n\n\nprint(\"\\nPerformance Metrics Breakdown for MobileNetV2:\")\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1-Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:49:23.901210Z","iopub.execute_input":"2025-04-06T11:49:23.901526Z","iopub.status.idle":"2025-04-06T11:49:23.927696Z","shell.execute_reply.started":"2025-04-06T11:49:23.901500Z","shell.execute_reply":"2025-04-06T11:49:23.926657Z"}},"outputs":[{"name":"stdout","text":"\nPerformance Metrics Breakdown for MobileNetV2:\nAccuracy: 0.6474\nPrecision: 0.6527\nRecall: 0.6474\nF1-Score: 0.6451\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"print(\"\\nDetailed Classification Report for MobileNetBase:\")\nprint(classification_report(y_test,y_pred_class))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:50:27.090960Z","iopub.execute_input":"2025-04-06T11:50:27.091271Z","iopub.status.idle":"2025-04-06T11:50:27.114363Z","shell.execute_reply.started":"2025-04-06T11:50:27.091246Z","shell.execute_reply":"2025-04-06T11:50:27.113505Z"}},"outputs":[{"name":"stdout","text":"\nDetailed Classification Report for MobileNetBase:\n              precision    recall  f1-score   support\n\n           0       0.87      0.90      0.89       100\n           1       0.70      0.85      0.77       100\n           2       0.67      0.49      0.57       100\n           3       0.47      0.55      0.50       100\n           4       0.33      0.50      0.40       100\n           5       0.64      0.63      0.64       100\n           6       0.75      0.58      0.66       100\n           7       0.75      0.65      0.70       100\n           8       0.79      0.75      0.77       100\n           9       0.84      0.81      0.82       100\n          10       0.53      0.51      0.52       100\n          11       0.39      0.43      0.41       100\n          12       0.75      0.71      0.73       100\n          13       0.66      0.48      0.55       100\n          14       0.58      0.69      0.63       100\n          15       0.59      0.62      0.60       100\n          16       0.77      0.74      0.76       100\n          17       0.78      0.86      0.82       100\n          18       0.69      0.63      0.66       100\n          19       0.77      0.64      0.70       100\n          20       0.82      0.82      0.82       100\n          21       0.69      0.85      0.76       100\n          22       0.74      0.78      0.76       100\n          23       0.77      0.75      0.76       100\n          24       0.77      0.85      0.81       100\n          25       0.60      0.50      0.55       100\n          26       0.61      0.63      0.62       100\n          27       0.45      0.44      0.45       100\n          28       0.76      0.84      0.80       100\n          29       0.68      0.64      0.66       100\n          30       0.56      0.54      0.55       100\n          31       0.66      0.61      0.64       100\n          32       0.63      0.55      0.59       100\n          33       0.70      0.46      0.55       100\n          34       0.64      0.74      0.69       100\n          35       0.56      0.28      0.37       100\n          36       0.67      0.75      0.71       100\n          37       0.65      0.66      0.66       100\n          38       0.53      0.56      0.55       100\n          39       0.93      0.89      0.91       100\n          40       0.71      0.70      0.71       100\n          41       0.81      0.88      0.84       100\n          42       0.58      0.66      0.62       100\n          43       0.50      0.75      0.60       100\n          44       0.49      0.40      0.44       100\n          45       0.50      0.53      0.51       100\n          46       0.47      0.52      0.50       100\n          47       0.56      0.46      0.51       100\n          48       0.85      0.86      0.86       100\n          49       0.71      0.75      0.73       100\n          50       0.53      0.36      0.43       100\n          51       0.65      0.75      0.70       100\n          52       0.46      0.78      0.58       100\n          53       0.77      0.92      0.84       100\n          54       0.70      0.69      0.70       100\n          55       0.32      0.29      0.31       100\n          56       0.80      0.79      0.79       100\n          57       0.76      0.73      0.74       100\n          58       0.78      0.73      0.76       100\n          59       0.52      0.34      0.41       100\n          60       0.75      0.77      0.76       100\n          61       0.74      0.67      0.70       100\n          62       0.60      0.66      0.63       100\n          63       0.61      0.55      0.58       100\n          64       0.51      0.53      0.52       100\n          65       0.63      0.37      0.47       100\n          66       0.59      0.68      0.63       100\n          67       0.59      0.57      0.58       100\n          68       0.83      0.82      0.82       100\n          69       0.75      0.74      0.74       100\n          70       0.65      0.72      0.69       100\n          71       0.74      0.60      0.66       100\n          72       0.37      0.34      0.35       100\n          73       0.55      0.56      0.55       100\n          74       0.40      0.44      0.42       100\n          75       0.84      0.80      0.82       100\n          76       0.84      0.79      0.81       100\n          77       0.62      0.63      0.62       100\n          78       0.46      0.73      0.57       100\n          79       0.75      0.64      0.69       100\n          80       0.41      0.43      0.42       100\n          81       0.63      0.66      0.64       100\n          82       0.79      0.89      0.84       100\n          83       0.75      0.52      0.62       100\n          84       0.67      0.53      0.59       100\n          85       0.70      0.74      0.72       100\n          86       0.89      0.73      0.80       100\n          87       0.77      0.83      0.80       100\n          88       0.73      0.66      0.69       100\n          89       0.61      0.83      0.71       100\n          90       0.62      0.68      0.65       100\n          91       0.74      0.75      0.74       100\n          92       0.63      0.50      0.56       100\n          93       0.64      0.53      0.58       100\n          94       0.78      0.93      0.85       100\n          95       0.67      0.60      0.63       100\n          96       0.43      0.40      0.41       100\n          97       0.59      0.69      0.64       100\n          98       0.40      0.43      0.42       100\n          99       0.74      0.75      0.74       100\n\n    accuracy                           0.65     10000\n   macro avg       0.65      0.65      0.65     10000\nweighted avg       0.65      0.65      0.65     10000\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}